\chapter{Background}
\label{sec:background}
Before proceeding to the description of our method, it is essential to understand methods
for cross-lingual named entity recognition that have been already proposed. This chapter will provide
an overview of several significant results and approaches in this field. However, this list is not
exhaustive, as XLNER remains an active area of research.

Overall, all approaches can be categorized into two major groups: model-based and data-based methodologies.

\section{Model transfer}
Currently, there are two main types of models used for the  NER problem. Both types are based on the
Transformer \cite{vaswani2017attention} architecture but leverage different components of it.

Encoder-only models, such as BERT \cite{devlin-etal-2019-bert}, are pretrained in unsupervised
settings using large volumes of text, which enhances their understanding of language.
Following this pretraining, these models are fine-tuned for the NER task, requiring a labeled
dataset for this process.

Conversely, decoder-only models, such as LLMs like GPT \cite{gpt3}, are pretrained in unsupervised
settings on even larger datasets. NER tasks can be performed by these models in a generative context,
utilizing both simple prompting as well advanced formulation, e. g. as a task of code generation, as in
GoLLIE \cite{sainz2024gollieannotationguidelinesimprove}, thereby eliminating the necessity for a
labeled NER dataset. Additionally, a notable advantage of decoder-only
models is their flexibility, i.e. they are not restricted to a predefined set of classes, unlike
encoder-only models, which can only predict classes that were included in the training dataset.

However, due to their autoregressive nature, large language models require significant computational
resources to perform the NER task, as they necessitate several forward passes of the model. In contrast,
encoder-only models accomplish this in a single forward pass. To address the issue of resource
requirements, some researchers have proposed distilling a large LLM into smaller LLMs, e. g. UniversalNER \cite{zhou2023universalner},
or even into encoder-only models \cite{huang2024leveraginglargelanguagemodels}.

In the context of cross-lingual NER, both approaches leverage the model's ability to transfer knowledge
across languages. The general concept is as follows: models are pretrained on datasets containing
multiple languages, thereby developing an understanding of each language. Subsequently, if a model
is trained as in the case of BERT-like architectures, or is capable, as is the case of large language models,
of addressing the NER problem in one language it can subsequently transfer this knowledge to tackle
NER in other languages. Notable examples of such encoder-only models include mBERT
\cite{devlin-etal-2019-bert}, XLM-RoBERTa \cite{conneau-etal-2020-unsupervised-xlmr}, and
MDeBERTa \cite{He2020DeBERTaDB,He2021DeBERTaV3ID}. Additionally, the pretraining datasets
of all LLMs typically \cite{touvron2023llama2openfoundation} contain data in multiple languages.

It has been demonstrated by \cite{torge-etal-2023-named} that when the language of the dataset used for the
fine-tuning of an encoder-only model originates from the same language family as the target
language, the performance of NER in the target language is likely to be higher compared to situations
where the dataset is sourced from a different language family. Unfortunately, for low-resource
languages such as Upper Sorbian, the languages within the same family also lack sufficient labeled data.
A similar situation arises in specific domains, where labeled data is predominantly available only in English.
The multilingual capability of LLMs for low-resource languages is also limited,
and this topic constitutes an active area of research \cite{lai-etal-2024-llms}.

Thus, despite the fact that model transfer demonstrates favorable results in some
scenarios \cite{garcia-ferrero-etal-2022-model}, the issues associated with these methods
underscore the necessity for alternative approaches to XLNER.

\section{Data-based methods}

Another significant group of approaches to cross-lingual named entity recognition consists of methods
aimed at generating labeled datasets in the target language, referred to as data-based methods.
While some approaches generate entirely artificial data, such as MulDA~\cite{liu-etal-2021-mulda},
in which the authors propose using a language model (LSTM \cite{lstm} or
mBART~\cite{liu-etal-2020-multilingual-denoising}) to generate labelled text in the target language by
inserting labels in IOB2 format before the words with corresponding labels, the most compelling approaches
not only generate text but also incorporate the labeling of the desired text in the target language.

The overall pipeline of such XLNER approaches is divided into
three steps: the translation of the input sentence, referred to as the target sentence, into a
high-resource language; the application of a NER model to the translated
sentence, known as the source sentence; and the projection of entities from the source sentence
back onto the sentence in the target language.

The NER entities identified by a NER model in the source sentence are referred to as source entities.
\begin{definition}[Source entity]
  Let \( \src{s} = \left( \src{s_1}, \dots, \tgt{s_m} \right) \) be a source sentence consisting of \( n \) words
  and \( L \) -- a fixed set of classes.
  The source entity \( \src{p} = (i_{\src{p}}, j_{\src{p}}, l_{\src{p}} ) \) is defined as a continuous
  subrange of words within the sentence, that corresponds to entity predicted by a NER model. It is
  characterized by the index \( i_{\src{p}} \in \{ 1, \dots, n \} \) of the first
  word, the index \( j_{\src{p}} \in \{ 1, \dots, n \} \) of the last word and the class \( l_{\src{p}} \in L \).
\end{definition}

This type of XLNER pipeline is called a projection-based pipeline. The main idea is that after
translation, a sentence is obtained in a high-resource language for which a labeled dataset is
likely available, therefore it is possible to train a model to perform the desired NER task.

While state-of-the-art transformer-based models, such as NLLB-200 \cite{nllbteam2022languageleftbehindscaling}
and DeBERTa \cite{He2020DeBERTaDB,He2021DeBERTaV3ID}, are utilized for translation and source NER labelling,
there are numerous methods to perform the final projection step. This work will propose a formulation
of the projection step as an integer linear optimization problem, thereby necessitating a description
of the existing projection methods. The first major group of projection methods consists of those based
on back-translation, which involves translating labeled source sentences or their substrings back to the
target language while preserving the labels.

CROP \cite{yang-etal-2022-crop} surrounds each source entity with a special symbol \texttt{\_\_SLOT{n}\_\_},
where \( n \) represents an index corresponding to the entity class. Subsequently, this slotted sentence
is passed to a fine-tuned translation model designed to translate such sentences, resulting in a
sentence in the target language. Projection occurs in the following manner: for each substring
surrounded by slots with the same index, CROP searches for it in the original target sentence. If it
is found, the class corresponding to the index of the slot is assigned to the identified substring;
otherwise, no projection occurs. A significant weakness of CROP is that the back-translated sentence
often differs from the original sentence, leading to low recall and the omission of many entities.

EasyProject \cite{chen-etal-2023-frustratingly} also employs the insertion of special markers,
specifically square brackets, which here remain consistent across different entity types, surrounding all
source entities before passing the marked sentence into the translation
model. The model then translates the entire sentence with the markers and also translates each source
entity independently. Subsequently, fuzzy string matching is utilized to project labels: for each substring
of the back-translated sentence that is surrounded by markers, the method identifies the back-translated
source entity with the highest fuzzy matching string score and assigns the corresponding label to the substring.
Unfortunately, this method also suffers from translation errors induced by the insertion of special
symbols, as well as the fact that translating source entities independently, without context, often
results in lower-quality translations. By its design, this method is incapable of projecting labels
onto the original sentence and can therefore only be employed to generate a labeled dataset in the target language
based on the labeled dataset in the source language.

CODEC \cite{Le2024ConstrainedDF} aims to address the issue that the back-translated and the original
target sentences differ by employing constrained decoding. This method similarly encloses every entity
with special markers that corresponds to the class; however, it utilizes guided decoding
(for which the authors propose an optimized version specifically for this task) to ensure that
the back-translated sentence completely matches the original target sentence, except for the markers
added around each entity. Nevertheless, since translation models remain imperfect and the insertion
of markers impacts their performance, this method also exhibits limitations.

CLaP \cite{parekh-etal-2024-contextual} seeks to address the issue of independent source entity
translation encountered in EasyProject by proposing the use of a LLM as a contextualized translator
instead of employing a conventional translation model like NLLB-200. In this approach, the LLM is tasked
with translating each source entity into the target language while being provided with the entire
source sentence as context. Initially, this method was proposed to generate a labeled dataset in the
target language based on a labeled dataset in the source language. However, with the application of
guided decoding that constrains the translation of source entities to be substrings of the original
sentence, it can also be utilized for projection onto the original target sentence. The primary
limitation of this approach lies in the language coverage of openly available LLMs, which typically \cite{touvron2023llama2openfoundation}
encompasses fewer than 200 languages, compared to NLLB-200, along with the fact that translation
quality is still not perfect.

T-Projection \cite{garcia-ferrero-etal-2023-projection} employs a fine-tuned mT5 \cite{xue-etal-2021-mt5}
model with beam search to generate substrings of the target sentence that serve as potential candidates for matching
with source entities. It then computes the NMTScore \cite{vamvas_sennrich_2022_nmtscore}, which
represents the likelihood that the given source entity translates to the selected candidate, ultimately
choosing the candidate with the highest NMTScore to project the source entity onto it. The primary
drawbacks of this approach include the limitation of the mT5 model in terms of the number of languages
it supports, the necessity for the model to be trained, and the significant computational resources
required to generate just potential projection candidates. Additionally, the NMTScore is not without its
flaws, as it is dependent on the quality of the underlying translation model.

As an alternative to translation-based projection, TransFusion \cite{transfusion} proposes the use of
specifically trained models to perform projection. The authors propose two types of fusion
models capable of projecting entities: decoder-only large language models and encoder-only models.
In the first case, the translated sentence in the source language and the original target sentence are
passed to the LLM, which is then asked to perform source NER labeling and projection simultaneously
by outputting labelling for both sentences. For the encoder-only model, every source entity is enclosed
with XML tags corresponding to classes, and this is concatenated with the original target sentence
before being passed to the encoder-only model. And then only the output that corresponds to the
target sentence is considered. The main limitation of this approach is that it requires a parallel labeled dataset
for training such models, which does not exist, which motivates the problem of XLNER. To address this fundamental issue, the
authors employ EasyProject to generate such a dataset based on a labeled dataset in the source
language. However, as EasyProject introduces errors, models trained on this generated data are also
affected by these inaccuracies.

\begin{algorithm}
  \SetAlgorithmName{Algorithm}{}{}
  \caption{Algorithm that merges ranges that are separated by \( d \) non-aligned to the source entity words}
  \label{alg:merge}

  \KwData{\( C \) -- set of ranges of target words,
    \( a _{kl} \) -- word-to-word alignments, \( e \) -- index of the first word of the source entity,
  parameters \( d \in \mathbb{N}, \text{only\_i} \in \{ True, False \} \)}
  \KwResult{\( \hat{C} \) -- set of target word ranges where all ranges with at most \(d\)
  non-aligned to the source words have been merged}

  \( \mathcal{C} \gets \) sort ranges \(C\) by the index of the first word \;
  \( \hat{C} \gets \{ \mathcal{C}[0] \} \)  \;
  \( \hat{o} \gets o_{\mathcal{C}[0]} \) \;
  \ForAll{\( (s, o) \in \mathcal{C} \)}
  {
    \uIf{\( s - \hat{o} > d \) }{
      \( \hat{C} \gets \hat{C} \cup \{ (s, o) \} \) \;
    }
    \uElseIf{only\_i is True and \( a_{es} = 1 \)}{
      \( \hat{C} \gets \hat{C} \cup \{ (s, o) \} \) \Comment*[r]{The first word is aligned to a source word with a \textit{B-} label}  \
    }
    \Else{
      \( c^* \gets \) last added to \( \hat{C} \) \;
      \( \hat{C} \gets \hat{C} \setminus \{ c^* \}  \) \;
      \( \hat{C} \gets \hat{C} \cup \{ (c^*_s, o) \}  \) \Comment*[r]{Merge ranges}  \
    }
    \( \hat{o} \gets o \) \;
  }
\end{algorithm}

The final type of projection approaches is based on word-to-word alignments, which indicate whether a
word in the source sentence corresponds to a word in the target sentence. The most effective methods
for computing such alignments today involve neural network-based aligners, such as
AWESoME \cite{dou-neubig-2021-word} and SimAlign \cite{jalili-sabet-etal-2020-simalign}.
Here and in the following sections, alignments will be represented by an alignment matrix \( a_{kl} \), where
each value is binary, indicating whether a word from the source sentence with
index \( k \) is aligned to a word in the target sentence with index \( l \).

The core idea of this projection framework is rooted in the property that if words are aligned with
one another, they should share the same label. However, since word-to-word alignments
generated by models are not yet ideal, this approach
encounters three primary challenges: split annotations, annotation collisions, and incorrect alignments.
Split annotations refer to a situation in which a single source entity corresponds to multiple words
from different parts of a target sentence, contrary to the expectation of a single continuous range
of words. This phenomenon occurs when there is a missing alignment for a middle word within the
range of words in the target sentence.
Annotation collisions happen when a word in the target sentence aligns with words from different source
entities, each having distinct labels. Incorrect alignments refer to situations where a word in the
target sentence is wrongly aligned with a word from a source entity.

The projection utilizing word-to-word alignments is carried out through a heuristic algorithm described
by \cite{garcia-ferrero-etal-2022-model}. This algorithm (Algorithm \ref{alg:heuristics}) addresses
split annotations by merging word ranges separated by a maximum of \( d \) words that are not aligned
to any word from the source entity. A detailed merging process is provided in Algorithm \ref{alg:merge},
which includes an additional parameter, \texttt{only\_i}, indicating whether the first word of the
right-side merging range can be aligned with the first word of the source entity that has a label
\textit{B-}.

Annotation collisions are managed by assigning the label to the longest continuous aligned range.
In the formulation of the algorithm that we present, this property is generalized, allowing for either the omission of
any limits or the selection of the top-k continuous aligned ranges by length.

Furthermore, the original algorithm is extended to address incorrect alignments by introducing an
optional threshold \( thr \) for the length ratio between a source entity and the corresponding range of words
in the target sentence. Since a one-to-one correspondence in the number of words is typically expected
for languages with similar writing systems, a small ratio generally indicates the presence of a single
incorrectly aligned word.

\begin{algorithm}
  \SetAlgorithmName{Algorithm}{}{}
  \caption{Heuristic projection algorithm based on word-to-word alignments}
  \label{alg:heuristics}

  \KwData{\( S \) -- set of source entities,
  \( a _{kl} \) -- word-to-word alignments, parameters \( d, k \in \mathbb{N}, \text{only\_i} \in \{ True, False \}, thr \in [0, 1] \)}
  \KwResult{\( \tgt{l} = (\tgt{l_1}), \dots, \tgt{l_m} \) -- labelling of the target sentence}

  \ForAll{\( \tgt{l_i} \in \tgt{l} \)}{
    \( \tgt{l_i} \gets \text{O} \) \;
  }

  \ForAll{\( \src{p} \in S \)}{
    \Comment{Extract continuous ranges of maximum length of target words that are aligned to any word of the source
    entity}
    \( C^* \gets
      \left\{ (s, o) \Big| \forall r \in \{ s, \dots, o \} \;
        \exists i \in \{ i_{\src{p}}, \dots, j_{\src{p}} \}
    \; a_{ir} = 1 \right\} \) \;
    \( C \gets \left\{ (s, o) \in C^* \Big|
        \nexists (\hat{s}, \hat{o}) \in  C^* \;
    [s, o] \subset [\hat{s}, \hat{o}] \right\} \) \;

    \Comment{Merge ranges that are separated by \(d\) non-aligned words}
    \( C \gets \text{merge}(C, a_{kl},  i_{\src{p}}, d, \text{only\_i}) \) \;

    \Comment{Length ratio thresholding (optional)}
    \If{\( thr > 0 \)}
    {
      \( C \gets \left\{ (s, o) \in C \Big| \dfrac{o - s}{j_{\src{p}} - i_{\src{p}}} > thr \right\} \) \;
    }

    \Comment{Take only top-k longest aligned ranges (optional)}
    \If{\( k > 0 \)}
    {
      \( C \gets \text{sort} \; C \; \text{by length and take top} \; k \) \;
    }

    \Comment{Labelling}
    \ForAll{\( (s, o) \in C \)}
    {
      \Comment{Label the range only if any word of it has not been previously labeled.}
      \If{\( \forall r \in \{ s, \dots, o \} \quad l_r = \text{O} \)}
      {
        \( \hat{l} \gets l_{\src{p}} \) \Comment*[r]{Class of the source entity}  \
        \( l_s \gets \text{B-} \hat{l} \) \Comment*[r]{Assign the \textit{B-} label to the first word} \
        \ForAll{\( r \in \{ s+1, o \} \)}
        {
          \( l_r \gets \text{I-} \hat{l} \) \Comment*[r]{Assign the \textit{I-} label to consecutive words} \
        }
      }
    }
  }
\end{algorithm}
